{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9091f8c4",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Recommender System\n",
    "\n",
    "In general, Collaborative filtering (CF) is more commonly used than content-based systems because it usually gives better results and is relatively easy to understand (from an overall implementation perspective). The algorithm has the ability to do feature learning on its own, which means that it can start to learn for itself what features to use. \n",
    "\n",
    "CF can be divided into **Memory-Based Collaborative Filtering** and **Model-Based Collaborative filtering**. \n",
    "\n",
    "In this tutorial, we will implement Model-Based CF by using singular value decomposition (SVD) and Memory-Based CF by computing cosine similarity. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "605a336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出多个output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "#Open hinterland\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8015ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703aa02",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65d8a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('u.data', sep='\\t', names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c384ec46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        0       50       5  881250949\n",
       "1        0      172       5  881250949\n",
       "2        0      133       1  881250949\n",
       "3      196      242       3  881250949\n",
       "4      186      302       3  891717742"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b222778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id              title\n",
       "0        1   Toy Story (1995)\n",
       "1        2   GoldenEye (1995)\n",
       "2        3  Four Rooms (1995)\n",
       "3        4  Get Shorty (1995)\n",
       "4        5     Copycat (1995)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = pd.read_csv(\"Movie_Id_Titles\")\n",
    "movie_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee23268d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>880473582</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>891271545</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>888552084</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>879362124</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>840</td>\n",
       "      <td>1674</td>\n",
       "      <td>4</td>\n",
       "      <td>891211682</td>\n",
       "      <td>Mamma Roma (1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>655</td>\n",
       "      <td>1640</td>\n",
       "      <td>3</td>\n",
       "      <td>888474646</td>\n",
       "      <td>Eighth Day, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>655</td>\n",
       "      <td>1637</td>\n",
       "      <td>3</td>\n",
       "      <td>888984255</td>\n",
       "      <td>Girls Town (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>655</td>\n",
       "      <td>1630</td>\n",
       "      <td>3</td>\n",
       "      <td>887428735</td>\n",
       "      <td>Silence of the Palace, The (Saimt el Qusur) (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>655</td>\n",
       "      <td>1641</td>\n",
       "      <td>3</td>\n",
       "      <td>887427810</td>\n",
       "      <td>Dadetown (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100003 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating  timestamp  \\\n",
       "0             0       50       5  881250949   \n",
       "1           290       50       5  880473582   \n",
       "2            79       50       4  891271545   \n",
       "3             2       50       5  888552084   \n",
       "4             8       50       5  879362124   \n",
       "...         ...      ...     ...        ...   \n",
       "99998       840     1674       4  891211682   \n",
       "99999       655     1640       3  888474646   \n",
       "100000      655     1637       3  888984255   \n",
       "100001      655     1630       3  887428735   \n",
       "100002      655     1641       3  887427810   \n",
       "\n",
       "                                                    title  \n",
       "0                                        Star Wars (1977)  \n",
       "1                                        Star Wars (1977)  \n",
       "2                                        Star Wars (1977)  \n",
       "3                                        Star Wars (1977)  \n",
       "4                                        Star Wars (1977)  \n",
       "...                                                   ...  \n",
       "99998                                   Mamma Roma (1962)  \n",
       "99999                              Eighth Day, The (1996)  \n",
       "100000                                  Girls Town (1996)  \n",
       "100001  Silence of the Palace, The (Saimt el Qusur) (1...  \n",
       "100002                                    Dadetown (1995)  \n",
       "\n",
       "[100003 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df,movie_titles,on='item_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc217fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of Users: 944\n",
      "Num of Movies: 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.nunique()\n",
    "n_items = df.item_id.nunique()\n",
    "\n",
    "print('Num. of Users:',n_users)\n",
    "print('Num of Movies:',n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02361399",
   "metadata": {},
   "source": [
    "Recommendation Systems by their very nature are very difficult to evaluate, but we will still show you how to evaluate them in this tutorial. In order to do this, we'll split our data into two sets. However, we won't do our classic X_train,X_test,y_train,y_test split. Instead we can actually just segement the data into two sets of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad17bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.25,random_state=1113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c46151c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75002, 5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b2df1",
   "metadata": {},
   "source": [
    "## Memory-Based Collaborative Filtering\n",
    "### Construct System\n",
    "\n",
    "Memory-Based Collaborative Filtering approaches can be divided into two main sections: **user-item filtering** and **item-item filtering**. \n",
    "\n",
    "A *user-item filtering* will take a particular user, find users that are similar to that user based on similarity of ratings, and recommend items that those similar users liked. \n",
    "\n",
    "In contrast, *item-item filtering* will take an item, find users who liked that item, and find other items that those users or similar users also liked. It takes items and outputs other items as recommendations. \n",
    "\n",
    "* *Item-Item Collaborative Filtering*: “Users who liked this item also liked …”\n",
    "* *User-Item Collaborative Filtering*: “Users who are similar to you also liked …”\n",
    "\n",
    "In both cases, you create a user-item matrix. Since we have split the data into testing and training we will need to create two ``[944 x 1682]`` matrices (all users by all movies). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c19419",
   "metadata": {},
   "source": [
    "After you have built the user-item matrix you calculate the similarity and create a similarity matrix. \n",
    "\n",
    "* For *Item-Item Collaborative Filtering* the similarity values between items are measured by observing all the users who have rated both items. \n",
    "\n",
    "* For *User-Item Collaborative Filtering* the similarity values between users are measured by observing all the items that are rated by both users.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5d6fd",
   "metadata": {},
   "source": [
    "A distance metric commonly used in recommender systems is *cosine similarity*, where the ratings are seen as vectors in ``n``-dimensional space and the similarity is calculated based on the angle between these vectors. \n",
    "Cosine similiarity for users *a* and *m* can be calculated using the formula below, where you take dot product of  the user vector *$u_k$* and the user vector *$u_a$* and divide it by multiplication of the Euclidean lengths of the vectors.\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?s_u^{cos}(u_k,u_a)=\\frac{u_k&space;\\cdot&space;u_a&space;}{&space;\\left&space;\\|&space;u_k&space;\\right&space;\\|&space;\\left&space;\\|&space;u_a&space;\\right&space;\\|&space;}&space;=\\frac{\\sum&space;x_{k,m}x_{a,m}}{\\sqrt{\\sum&space;x_{k,m}^2\\sum&space;x_{a,m}^2}}\"/>\n",
    "\n",
    "To calculate similarity between items *m* and *b* you use the formula:\n",
    "\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?s_u^{cos}(i_m,i_b)=\\frac{i_m&space;\\cdot&space;i_b&space;}{&space;\\left&space;\\|&space;i_m&space;\\right&space;\\|&space;\\left&space;\\|&space;i_b&space;\\right&space;\\|&space;}&space;=\\frac{\\sum&space;x_{a,m}x_{a,b}}{\\sqrt{\\sum&space;x_{a,m}^2\\sum&space;x_{a,b}^2}}\n",
    "\"/>\n",
    "\n",
    "Your first step will be to create the user-item matrix. Since you have both testing and training data you need to create two matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28e43bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=16543, user_id=893, item_id=294, rating=3, timestamp=874827789, title='Liar Liar (1997)')\n"
     ]
    }
   ],
   "source": [
    "#New Tricks\n",
    "for line in train_data.itertuples():\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c68d5051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = np.empty((n_users, n_items))\n",
    "train_data_matrix[:] = np.nan\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "test_data_matrix = np.empty((n_users, n_items))\n",
    "test_data_matrix[:] = np.nan\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c9295e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944, 1682)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(944, 1682)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_matrix.shape\n",
    "test_data_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676da45",
   "metadata": {},
   "source": [
    "**We should do mean normalization within each row**\n",
    "\n",
    "The idea here is that some users may tend always to give high or low ratings to all movies. The relative difference in the ratings that these users give is more important than the absolute values. To give an example: suppose, user *k* gives 4 stars to his favourite movies and 3 stars to all other good movies. Suppose now that another user *t* rates movies that he/she likes with 5 stars, and the movies he/she fell asleep over with 3 stars. These two users could have a very similar taste but treat the rating system differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f384fcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68dccfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_row_mean = np.nanmean(train_data_matrix,axis=1,keepdims=True)\n",
    "train_data_row_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d295ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_matrix = train_data_matrix - train_data_row_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37506e49",
   "metadata": {},
   "source": [
    "这里我们不对test_data_matrix做mean normalization, 在做预测的时候，把mean加回去即可\n",
    "\n",
    "之后，我们将所有的NaN替换为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69eff959",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_matrix[np.isnan(train_data_matrix)] = 0\n",
    "test_data_matrix[np.isnan(test_data_matrix)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "640dea17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46700508, -0.53299492,  0.46700508, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee9dbb",
   "metadata": {},
   "source": [
    "You can use the pairwise_distances function from sklearn to calculate the cosine similarity. Note, the output will range from 0 to 1 since the ratings are all positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "484cde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric=\"cosine\")\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d8787d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944, 1682)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(944, 944)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1682, 1682)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_matrix.shape\n",
    "user_similarity.shape\n",
    "item_similarity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba374c",
   "metadata": {},
   "source": [
    "Next step is to make predictions. You have already created similarity matrices: `user_similarity` and `item_similarity` and therefore you can make a prediction by applying following formula for user-based CF:\n",
    "\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?\\hat{x}_{k,m}&space;=&space;\\bar{x}_{k}&space;&plus;&space;\\frac{\\sum\\limits_{u_a}&space;sim_u(u_k,&space;u_a)&space;(x_{a,m}&space;-&space;\\bar{x_{u_a}})}{\\sum\\limits_{u_a}|sim_u(u_k,&space;u_a)|}\"/>\n",
    "\n",
    "We have do the mean normalization before, no more need to do here\n",
    "\n",
    "When making a prediction for item-based CF you don't need to correct for users average rating since query user itself is used to do predictions.\n",
    "\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?\\hat{x}_{k,m}&space;=&space;\\frac{\\sum\\limits_{i_b}&space;sim_i(i_m,&space;i_b)&space;(x_{k,b})&space;}{\\sum\\limits_{i_b}|sim_i(i_m,&space;i_b)|}\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dfd68fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        pred = similarity.dot(ratings) / np.sum(np.abs(similarity), axis=1, keepdims=True) + train_data_row_mean\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.sum(np.abs(similarity), axis=1) + train_data_row_mean\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "192ee465",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')\n",
    "item_prediction = predict(train_data_matrix, item_similarity, type='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23ec0433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.61517803, 3.50859547, 3.49510108, ..., 3.53173589, 3.53299492,\n",
       "        3.53299492],\n",
       "       [3.7321575 , 3.6184294 , 3.60709024, ..., 3.64313599, 3.64444444,\n",
       "        3.64444444],\n",
       "       [2.9576909 , 2.84376721, 2.83091969, ..., 2.86821191, 2.86956522,\n",
       "        2.86956522],\n",
       "       ...,\n",
       "       [4.30798268, 4.19637786, 4.18441749, ..., 4.22099304, 4.22222222,\n",
       "        4.22222222],\n",
       "       [3.47040886, 3.3592326 , 3.34830718, ..., 3.38333841, 3.38461538,\n",
       "        3.38461538],\n",
       "       [3.75326667, 3.64046312, 3.62886009, ..., 3.66539381, 3.66666667,\n",
       "        3.66666667]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[3.52722606, 3.53684779, 3.53468566, ..., 3.53323178, 3.53299492,\n",
       "        3.53299492],\n",
       "       [3.64410161, 3.64477848, 3.64497537, ..., 3.64431515, 3.64444444,\n",
       "        3.64444444],\n",
       "       [2.86957673, 2.86979867, 2.86943462, ..., 2.8691606 , 2.86956522,\n",
       "        2.86956522],\n",
       "       ...,\n",
       "       [4.22162022, 4.22241293, 4.22256792, ..., 4.22248708, 4.22222222,\n",
       "        4.22222222],\n",
       "       [3.38228779, 3.38574113, 3.38723682, ..., 3.38461538, 3.38461538,\n",
       "        3.38461538],\n",
       "       [3.66648991, 3.66673582, 3.66681465, ..., 3.66666667, 3.66666667,\n",
       "        3.66666667]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction\n",
    "item_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec8af2",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "There are many evaluation metrics but one of the most popular metric used to evaluate accuracy of predicted ratings is *Root Mean Squared Error (RMSE)*. \n",
    "<img src=\"https://latex.codecogs.com/gif.latex?RMSE&space;=\\sqrt{\\frac{1}{N}&space;\\sum&space;(x_i&space;-\\hat{x_i})^2}\" title=\"RMSE =\\sqrt{\\frac{1}{N} \\sum (x_i -\\hat{x_i})^2}\" />\n",
    "\n",
    "Since you only want to consider predicted ratings that are in the test dataset, you filter out all other elements in the prediction matrix with `prediction[ground_truth.nonzero()]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dac74199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0780c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 1.0215457056441115\n",
      "Item-based CF RMSE: 1.039878435708755\n"
     ]
    }
   ],
   "source": [
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de46e7",
   "metadata": {},
   "source": [
    "### How to recommend\n",
    "\n",
    "Now we have two results from Item-Item and User-Item collaborative filtering, let's give some recommendation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "812cf489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>944 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                              ...   \n",
       "0         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
       "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN  ...   \n",
       "940       NaN   NaN   NaN   2.0   NaN   NaN   4.0   5.0   3.0   NaN  ...   \n",
       "941       5.0   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   \n",
       "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "943       NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN  ...   \n",
       "\n",
       "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "user_id                                                              \n",
       "0         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "940       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "941       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "943       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[944 rows x 1682 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviemat = df.pivot_table(index='user_id',columns='item_id',values='rating')\n",
    "moviemat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27a00f",
   "metadata": {},
   "source": [
    "我们要给user_id = 0的人进行推荐5个电影，首先使用User-Item collaborative filtering来推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7462b955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Gone with the Wind (1939)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  item_id  rating  timestamp                            title\n",
       "0          0       50       5  881250949                 Star Wars (1977)\n",
       "584        0      172       5  881250949  Empire Strikes Back, The (1980)\n",
       "952        0      133       1  881250949        Gone with the Wind (1939)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"user_id\"]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4157dd4f",
   "metadata": {},
   "source": [
    "0号用户很喜欢星球大战一类的冒险动作片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "34a6a621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 49, 173, 126,  99,  97, 317, 312,  63, 482, 171])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#因为可能推荐的电影用户0看过，所以我们选出前10的推荐电影\n",
    "user_prediction[0].argsort()[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "472731d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50, 174, 127, 100,  98, 318, 313,  64, 483, 172])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#前10电影的item_id\n",
    "user_0_item_id = user_prediction[0].argsort()[-10:][::-1] + 1\n",
    "user_0_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c740e6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       50\n",
       "584    172\n",
       "952    133\n",
       "Name: item_id, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[174, 127, 100, 98, 318, 313, 64, 483]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#去除掉看过的电影\n",
    "df[df[\"user_id\"]==0][\"item_id\"]\n",
    "diff = set(user_0_item_id) - set(df[df[\"user_id\"]==0][\"item_id\"])\n",
    "[item for item in user_0_item_id if item in diff]\n",
    "user_item_results = [item for item in user_0_item_id if item in diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "46bc7cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Raiders of the Lost Ark (1981)']\n",
      "['Godfather, The (1972)']\n",
      "['Fargo (1996)']\n",
      "['Silence of the Lambs, The (1991)']\n",
      "[\"Schindler's List (1993)\"]\n",
      "['Titanic (1997)']\n",
      "['Shawshank Redemption, The (1994)']\n",
      "['Casablanca (1942)']\n"
     ]
    }
   ],
   "source": [
    "for i in user_item_results:\n",
    "    movie = df[df[\"item_id\"]==i][\"title\"].unique()\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55078deb",
   "metadata": {},
   "source": [
    "***Users who are similar to you also like \"Raiders of the Lost Ark\", \"Godfather\", \"Fargo\".....***\n",
    "\n",
    "可以看出推荐的都是和星球大战为同一类型的影片\n",
    "\n",
    "再用Item-Item的方法推荐一下影片:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb083cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Theodore Rex (1995)']\n",
      "['Nadja (1994)']\n",
      "['Turbo: A Power Rangers Movie (1997)']\n",
      "['D3: The Mighty Ducks (1996)']\n",
      "['Free Willy 2: The Adventure Home (1995)']\n",
      "['Flipper (1996)']\n",
      "['Operation Dumbo Drop (1995)']\n",
      "['Batman Forever (1995)']\n",
      "['Kull the Conqueror (1997)']\n",
      "['Batman Returns (1992)']\n"
     ]
    }
   ],
   "source": [
    "item_0_item_id = item_prediction[0].argsort()[-10:][::-1] + 1\n",
    "diff = set(item_0_item_id) - set(df[df[\"user_id\"]==0][\"item_id\"])\n",
    "item_item_results = [item for item in item_0_item_id if item in diff]\n",
    "for i in item_item_results:\n",
    "    movie = df[df[\"item_id\"]==i][\"title\"].unique()\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b150b",
   "metadata": {},
   "source": [
    "***Users who liked this item also liked \"Theodore Rex\", \"Nadja\"....***\n",
    "\n",
    "从效果上来看并不是很好的推荐，可能是应为该用户对电影的rating很少，导致结果并不准确"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c8479a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "每当加进来新的用户，就把matrix更新一下重新拟合模型，然后根据最新的模型给出推荐，如果新加入的用户没有对任何电影做rating，那么将无法实现推荐\n",
    "\n",
    "---\n",
    "\n",
    "Memory-based algorithms are easy to implement and produce reasonable prediction quality. \n",
    "The drawback of memory-based CF is that it doesn't scale to real-world scenarios and doesn't address the well-known cold-start problem, that is when new user or new item enters the system. Model-based CF methods are scalable and can deal with higher sparsity level than memory-based models, but also suffer when new users or items that don't have any ratings enter the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038bca70",
   "metadata": {},
   "source": [
    "## Model-Based Collaborative Filtering\n",
    "\n",
    "Model-based Collaborative Filtering is based on **matrix factorization (MF)** which has received greater exposure, mainly as an unsupervised learning method for latent variable decomposition and dimensionality reduction. Matrix factorization is widely used for recommender systems where it can deal better with scalability and sparsity than Memory-based CF. The goal of MF is to learn the latent preferences of users and the latent attributes of items from known ratings (learn features that describe the characteristics of ratings) to then predict the unknown ratings through the dot product of the latent features of users and items.(和吴恩达提到的方法思路一致)\n",
    "\n",
    "When you have a very sparse matrix, with a lot of dimensions, by doing matrix factorization you can restructure the  user-item matrix into low-rank structure, and you can represent the matrix by the multiplication of two low-rank matrices, where the rows contain the latent vector. You fit this matrix to approximate your original matrix, as closely as possible, by multiplying the low-rank matrices together, which fills in the entries missing in the original matrix.\n",
    "\n",
    "Let's calculate the sparsity level of MovieLens dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ae4f5871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of MovieLens100K is 93.7%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(df)/float(n_users*n_items),3)\n",
    "print('The sparsity level of MovieLens100K is ' +  str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4e76cb",
   "metadata": {},
   "source": [
    "To give an example of the learned latent preferences of the users and items: let's say for the MovieLens dataset you have the following information: _(user id, age, location, gender, movie id, director, actor, language, year, rating)_. By applying matrix factorization the model learns that important user features are _age group (under 10, 10-18, 18-30, 30-90)_, _location_ and _gender_, and for movie features it learns that _decade_, _director_ and _actor_ are most important. Now if you look into the information you have stored, there is no such feature as the _decade_, but the model can learn on its own. The important aspect is that the CF model only uses data (user_id, movie_id, rating) to learn the latent features. If there is little data available model-based CF model will predict poorly, since it will be more difficult to learn the latent features. \n",
    "\n",
    "Models that use both ratings and content features are called **Hybrid Recommender Systems** where both Collaborative Filtering and Content-based Models are combined. Hybrid recommender systems usually show higher accuracy than Collaborative Filtering or Content-based Models on their own: they are capable to address the cold-start problem better since if you don't have any ratings for a user or an item you could use the metadata from the user or item to make a prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd176e",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cc0dde",
   "metadata": {},
   "source": [
    "A well-known matrix factorization method is **Singular value decomposition (SVD)**. Collaborative Filtering can be formulated by approximating a matrix `X` by using singular value decomposition. The winning team at the Netflix Prize competition used SVD matrix factorization models to produce product recommendations, for more information I recommend to read articles: [Netflix Recommendations: Beyond the 5 stars](http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html) and [Netflix Prize and SVD](http://buzzard.ups.edu/courses/2014spring/420projects/math420-UPS-spring-2014-gower-netflix-SVD.pdf).\n",
    "The general equation can be expressed as follows:\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?X=USV^T\" title=\"X=USV^T\" />\n",
    "\n",
    "\n",
    "Given `m x n` matrix `X`:\n",
    "* *`U`* is an *`(m x r)`* orthogonal matrix\n",
    "* *`S`* is an *`(r x r)`* diagonal matrix with non-negative real numbers on the diagonal\n",
    "* *V^T* is an *`(r x n)`* orthogonal matrix\n",
    "\n",
    "Elements on the diagnoal in `S` are known as *singular values of `X`*. \n",
    "\n",
    "\n",
    "Matrix *`X`* can be factorized to *`U`*, *`S`* and *`V`*. The *`U`* matrix represents the feature vectors corresponding to the users in the hidden feature space and the *`V`* matrix represents the feature vectors corresponding to the items in the hidden feature space.\n",
    "\n",
    "\n",
    "Then you can make a prediction by taking dot product of *`U`*, *`S`* and *`V^T`*.\n",
    "\n",
    "这个方法和吴恩达的区别在于，吴恩达 only learn the latent features of the movies, 而SVD方法会学习user和movie的feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a1a0079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#Get SVD components from train matrix. Choose k\n",
    "u, s, vt = svds(train_data_matrix, k=20)\n",
    "s_diag_matrix = np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt) + train_data_row_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1247dc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.07877653, 3.6176229 , 3.4347678 , ..., 3.53942189, 3.53299492,\n",
       "        3.53299492],\n",
       "       [3.91351977, 3.63834105, 3.51985329, ..., 3.6402315 , 3.64444444,\n",
       "        3.64444444],\n",
       "       [2.79662335, 2.83213578, 2.84867429, ..., 2.88089511, 2.86956522,\n",
       "        2.86956522],\n",
       "       ...,\n",
       "       [4.26522008, 4.21010365, 4.26755048, ..., 4.22417162, 4.22222222,\n",
       "        4.22222222],\n",
       "       [3.93332032, 3.11645104, 3.16984426, ..., 3.39270767, 3.38461538,\n",
       "        3.38461538],\n",
       "       [3.74206219, 3.65048066, 3.6653656 , ..., 3.66790903, 3.66666667,\n",
       "        3.66666667]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(944, 1682)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred\n",
    "X_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c531f6",
   "metadata": {},
   "source": [
    "**Evaluation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "385a7b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Based CF RMSE: 0.9881610373528238\n"
     ]
    }
   ],
   "source": [
    "print('Model-Based CF RMSE: ' + str(rmse(X_pred, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f767705",
   "metadata": {},
   "source": [
    "The RMSE is lower than the Memory-Based CF. However, carelessly addressing only the relatively few known entries is highly prone to overfitting. SVD can be very slow and computationally expensive. More recent work minimizes the squared error by applying alternating least square or stochastic gradient descent and uses regularization terms to prevent overfitting.\n",
    "\n",
    "Then, we also give the suggestions for the top 10 movies to user 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c752a169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Gone with the Wind (1939)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  item_id  rating  timestamp                            title\n",
       "0          0       50       5  881250949                 Star Wars (1977)\n",
       "584        0      172       5  881250949  Empire Strikes Back, The (1980)\n",
       "952        0      133       1  881250949        Gone with the Wind (1939)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"user_id\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d7538080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fargo (1996)']\n",
      "['Raiders of the Lost Ark (1981)']\n",
      "['Princess Bride, The (1987)']\n",
      "['Return of the Jedi (1983)']\n",
      "['Alien (1979)']\n",
      "['Sling Blade (1996)']\n",
      "['Swingers (1996)']\n",
      "['Usual Suspects, The (1995)']\n",
      "['Hunt for Red October, The (1990)']\n"
     ]
    }
   ],
   "source": [
    "Model_0_item_id = X_pred[0].argsort()[-10:][::-1] + 1\n",
    "diff = set(Model_0_item_id) - set(df[df[\"user_id\"]==0][\"item_id\"])\n",
    "Model_item_results = [item for item in Model_0_item_id if item in diff]\n",
    "for i in Model_item_results:\n",
    "    movie = df[df[\"item_id\"]==i][\"title\"].unique()\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d23236",
   "metadata": {},
   "source": [
    "***There are the movie recommendations for you: \"Fargo\", \"Raiders of the Lost Ark\"....***\n",
    "\n",
    "可以看出推荐的影片都是以冒险为主，效果很不错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb39a5",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "We did a great job:\n",
    "* We have covered how to implement simple **Collaborative Filtering** methods, both memory-based CF and model-based CF.\n",
    "* **Memory-based models** are based on similarity between items or users, where we use cosine-similarity.\n",
    "* **Model-based CF** is based on matrix factorization where we use SVD to factorize the matrix.\n",
    "* Building recommender systems that perform well in cold-start scenarios (where little data is available on new users and items) remains a challenge. The standard collaborative filtering method performs poorly is such settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a8a83",
   "metadata": {},
   "source": [
    "## More References\n",
    "\n",
    "If you want to tackle your own recommendation system analysis, check out these data sets. Note: The files are quite large in most cases, not all the links may stay up to host the data, but the majority of them still work. Or just Google for your own data set!\n",
    "\n",
    "**Movies Recommendation:**\n",
    "\n",
    "MovieLens - Movie Recommendation Data Sets http://www.grouplens.org/node/73\n",
    "\n",
    "Yahoo! - Movie, Music, and Images Ratings Data Sets http://webscope.sandbox.yahoo.com/catalog.php?datatype=r\n",
    "\n",
    "Jester - Movie Ratings Data Sets (Collaborative Filtering Dataset) http://www.ieor.berkeley.edu/~goldberg/jester-data/\n",
    "\n",
    "Cornell University - Movie-review data for use in sentiment-analysis experiments http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "**Music Recommendation:**\n",
    "\n",
    "Last.fm - Music Recommendation Data Sets http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/index.html\n",
    "\n",
    "Yahoo! - Movie, Music, and Images Ratings Data Sets http://webscope.sandbox.yahoo.com/catalog.php?datatype=r\n",
    "\n",
    "Audioscrobbler - Music Recommendation Data Sets http://www-etud.iro.umontreal.ca/~bergstrj/audioscrobbler_data.html\n",
    "\n",
    "Amazon - Audio CD recommendations http://131.193.40.52/data/\n",
    "\n",
    "**Books Recommendation:**\n",
    "\n",
    "Institut für Informatik, Universität Freiburg - Book Ratings Data Sets http://www.informatik.uni-freiburg.de/~cziegler/BX/\n",
    "Food Recommendation:\n",
    "\n",
    "Chicago Entree - Food Ratings Data Sets http://archive.ics.uci.edu/ml/datasets/Entree+Chicago+Recommendation+Data\n",
    "Merchandise Recommendation:\n",
    "\n",
    "**Healthcare Recommendation:**\n",
    "\n",
    "Nursing Home - Provider Ratings Data Set http://data.medicare.gov/dataset/Nursing-Home-Compare-Provider-Ratings/mufm-vy8d\n",
    "\n",
    "Hospital Ratings - Survey of Patients Hospital Experiences http://data.medicare.gov/dataset/Survey-of-Patients-Hospital-Experiences-HCAHPS-/rj76-22dk\n",
    "\n",
    "**Dating Recommendation:**\n",
    "\n",
    "www.libimseti.cz - Dating website recommendation (collaborative filtering) http://www.occamslab.com/petricek/data/\n",
    "Scholarly Paper Recommendation:\n",
    "\n",
    "National University of Singapore - Scholarly Paper Recommendation http://www.comp.nus.edu.sg/~sugiyama/SchPaperRecData.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
